# -*- coding: utf-8 -*-
"""RL_Algorithm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-EaWElJDFmg1AVx5FKrK8v-f9NGh3oGn

**RL Algorithems with prediction user input**

*   TF-IDF for text feature extraction
*   Q-Learning as the RL algorithm
*   Simple state-action design for demonstration
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import numpy as np
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

import warnings
warnings.filterwarnings('ignore')

SEED = 41

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

"""# New Section

**Load Database/Import Data**
"""

from os.path import join
from google.colab import drive
drive.mount('/content/drive/')
#read the data
df=pd.read_csv('/content/drive/My Drive/FakeNews/datasets/train.csv')
df.head()

"""**Exploratory Data Analysis (EDA)**"""

df.describe()
df.info()
df.shape
#rows and columns
df.isnull().sum()
df=df.dropna()
df.isnull().sum()
df['label'].hist()
_ = sns.countplot(x="label", data=df)

# WordCloud
text = df.text[0]
wordcloud = WordCloud().generate(text)
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

# Combine title and text (if 'text' exists)
df['content'] = df['title'].fillna('') + ' ' + df.get('text', '').fillna('')

"""**Data Preprocessing/Feature Engineering**"""

# Basic text preprocessing
def clean_text(text):
    text = re.sub(r'[^\w\s]', '', text)
    return text.lower()

df['clean_content'] = df['content'].apply(clean_text)

# Encode labels
le = LabelEncoder()
df['label_enc'] = le.fit_transform(df['label'])  # 1: Real, 0: Fake

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(df['clean_content'], df['label_enc'], test_size=0.2, random_state=42)

# TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train).toarray()
X_test_tfidf = vectorizer.transform(X_test).toarray()

"""**2. Reinforcement Learning Setup (Q-Learning)**"""

class FakeNewsEnv:
    def __init__(self, data, labels):
        self.data = data
        self.labels = labels
        self.index = 0
        self.n_samples = len(data)

    def reset(self):
        self.index = 0
        return self.data[self.index]

    def step(self, action):
        # Use .iloc to access by position instead of label
        true_label = self.labels.iloc[self.index]
        reward = 1 if action == true_label else -1

        self.index += 1
        done = self.index >= self.n_samples
        # Use .iloc to access by position instead of label
        next_state = self.data[self.index] if not done else None

        return next_state, reward, done

"""**3. Q-Learning Agent**"""

class QAgent:
    def __init__(self, state_size, action_size):
        self.q_table = np.random.uniform(low=0, high=1, size=(state_size, action_size))
        self.action_size = action_size
        self.state_size = state_size

    def choose_action(self, state_idx, epsilon):
        if np.random.rand() < epsilon:
            return np.random.randint(self.action_size)
        return np.argmax(self.q_table[state_idx])

    def learn(self, state_idx, action, reward, next_state_idx, alpha, gamma):
        old_value = self.q_table[state_idx, action]
        next_max = np.max(self.q_table[next_state_idx]) if next_state_idx is not None else 0
        new_value = old_value + alpha * (reward + gamma * next_max - old_value)
        self.q_table[state_idx, action] = new_value

"""**4. Train the Q-Learning Agent**"""

# Simplify states using hash (for demo purpose, reduce dimensionality)
def state_index(vec):
    return int(np.sum(vec) * 1000) % 5000

env = FakeNewsEnv(X_train_tfidf, y_train)
agent = QAgent(state_size=5000, action_size=2)

alpha = 0.1  # Learning rate
gamma = 0.9  # Discount factor
epsilon = 0.2
episodes = 10

for ep in range(episodes):
    state = env.reset()
    total_reward = 0
    while True:
        state_idx = state_index(state)
        action = agent.choose_action(state_idx, epsilon)
        next_state, reward, done = env.step(action)
        next_state_idx = state_index(next_state) if not done else None
        agent.learn(state_idx, action, reward, next_state_idx, alpha, gamma)
        total_reward += reward
        if done:
            break
        state = next_state
    print(f"Episode {ep+1}: Total Reward = {total_reward}")

"""** 5. Evaluate the Agent **"""

# Evaluate on test data
correct = 0
for i in range(len(X_test_tfidf)):
    state_idx = state_index(X_test_tfidf[i])
    action = np.argmax(agent.q_table[state_idx])
    if action == y_test.iloc[i]:
        correct += 1

accuracy = correct / len(y_test)
print("Test Accuracy:", accuracy)

"""** 6. # Define prediction function **"""

# Define prediction function
def predict_fake_news(text):
    cleaned = clean_text(text)
    tfidf_vector = vectorizer.transform([cleaned]).toarray()[0]
    state_idx = state_index(tfidf_vector)
    action = np.argmax(agent.q_table[state_idx])
    label = le.inverse_transform([action])[0]
    return label

"""**7. Test**"""

sample_news = "Breaking: NASA discovers water on Mars"
prediction = predict_fake_news(sample_news)
print("Prediction:", prediction)

# multiple input
test_news_list = [
    "Government announces new healthcare policy",
    "Click here to win a free iPhone",
    "New study reveals benefits of meditation",
    "Aliens landed in my backyard last night"
]

for i, news in enumerate(test_news_list, 1):
    print(f"{i}. {news}")
    print("   âž¤ Prediction:", predict_fake_news(news))

"""**Save Mode for later use**"""

# Save Q-table

import pickle
pickle.dump(vectorizer, open('/content/drive/My Drive/FakeNews/RLModel/vectorizer.pkl', 'wb'))
pickle.dump(le, open('/content/drive/My Drive/FakeNews/RLModel/label_encoder.pkl', 'wb'))
np.save('/content/drive/My Drive/FakeNews/RLModel/q_table.npy', agent.q_table)
print("done")

# Test Reload Q-table
agent.q_table = np.load("/content/drive/My Drive/FakeNews/RLModel/q_table.npy")
print("loaded agina")

"""** lear add**"""

